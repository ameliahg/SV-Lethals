# Directions for future research

Multiple systems estimation has a number of challenges 

Selecting the appropriate set of strata to create a global estimate presents a sequence of methodological difficulties. Following Sekar and Deming's (1949) original recommendation, our practice has been to divide data into the smallest possible strata that have a minimum number of zero cells. Although we have followed approximately this approach in this paper, we identify a number of issues.

Perhaps most worryingly, the stratification approach we have chosen here may suffer from two faults. First, we may be misinterpreting the multimodality that triggers our stratification rules. Multiple modes in the posterior distribution of $\hat{N}$ represent differing estimates among different log-linear models. The differences may arise because the population being sampled in this stratum contains a mix of capture probabilities, as we proposed: different models are controlling for different subsets of the data with different capture probabilities, and these differences affect the list interactions, which then affect the estimate of the unobserved killings. However, the multimodality may also result from the stratum being too small. If the sample size is too small, there may be insufficient data to allow the cells of the $x_{ijkl}$ table to approximate the correct distribution to enable a reliable estimate of $x_{0000}$, the cell representing the unobserved killings. All else being equal, a smaller sample should result in higher variance; and the multimodality is one way higher variance may be seen. In this case, stratification does not control for heterogeneity, and it may worsen the weakness of estimates in already too-small strata.

A second, related problem with our stratification approach is that by making multiple comparisons, we may find strata that appear to fit well by chance. This is similar to what Gelman and Loken (2013) call the "garden of forking paths." One result of this problem is that, when we split a multi-modal stratum, the estimates of the new strata may have smaller variances than the original. Any data-driven stratification approach may be affected by this problem. One way to address the issue would be to test each candidate stratum for capture heterogeneity, then split when heterogeneity has been found. There might be a way to re-estimate the variances at the end, taking into consideration the test-driven stratification decisions. This approach might be similar to problems with inferences after model selection, or more generally, questions about inference after multiple comparisons (e.g., Lee et al. 2016).

A more general problem with multiple systems estimation is the assumption that all the elements of the population of interest have a probability greater than zero of being observed. Some members of the population might probabilities of observation so small that in practice they are very unlikely to ever be observed. Consequently, an estimate represents only the fraction of the population with a probability of observation above some minimum level, and further, the estimate is likely to be smaller than the true population size. Johndrow et al. (forthcoming) call the minimum probability of observation "alpha observability," and they have shown that by making explicit the level of alpha observability, the variance of the estimate can be greatly reduced. This is a classic example of balancing variance and bias: by making explicit the small downward bias, we can reduce the variance.


<!--done-->

